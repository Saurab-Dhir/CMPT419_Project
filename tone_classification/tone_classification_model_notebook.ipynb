{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tone Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\SFU\\Spring2025\\CMPT419\\Project\\ProjectCode\\CMPT419_Project\\419env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler  \n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from data_loader import Wav2Vec2FeatureExtractor, Wav2Vec2Dataset, collate_fn_wav2vec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "CREMA D + RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/CREMA\\1001_DFA_ANG_XX.wav</td>\n",
       "      <td>ang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/CREMA\\1001_DFA_DIS_XX.wav</td>\n",
       "      <td>dis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/CREMA\\1001_DFA_FEA_XX.wav</td>\n",
       "      <td>fea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/CREMA\\1001_DFA_HAP_XX.wav</td>\n",
       "      <td>hap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/CREMA\\1001_DFA_NEU_XX.wav</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file label\n",
       "0  data/CREMA\\1001_DFA_ANG_XX.wav   ang\n",
       "1  data/CREMA\\1001_DFA_DIS_XX.wav   dis\n",
       "2  data/CREMA\\1001_DFA_FEA_XX.wav   fea\n",
       "3  data/CREMA\\1001_DFA_HAP_XX.wav   hap\n",
       "4  data/CREMA\\1001_DFA_NEU_XX.wav   neu"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREMA-D data\n",
    "crema_dir = 'data/CREMA'\n",
    "crema_files = [f for f in os.listdir(crema_dir) if f.endswith('.wav')]\n",
    "def extract_crema_label(filename):\n",
    "    return filename.split('_')[2].replace('.wav', '').lower()\n",
    "\n",
    "df_crema = pd.DataFrame({\n",
    "    'file': [os.path.join(crema_dir, f) for f in crema_files],\n",
    "    'label': [extract_crema_label(f) for f in crema_files]\n",
    "})\n",
    "\n",
    "df_crema.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/RAVDESS/Actor_01\\03-01-01-01-01-01-01.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/RAVDESS/Actor_01\\03-01-01-01-01-02-01.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/RAVDESS/Actor_01\\03-01-01-01-02-01-01.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/RAVDESS/Actor_01\\03-01-01-01-02-02-01.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/RAVDESS/Actor_01\\03-01-03-01-01-01-01.wav</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file    label\n",
       "0   data/RAVDESS/Actor_01\\03-01-01-01-01-01-01.wav  neutral\n",
       "1   data/RAVDESS/Actor_01\\03-01-01-01-01-02-01.wav  neutral\n",
       "2   data/RAVDESS/Actor_01\\03-01-01-01-02-01-01.wav  neutral\n",
       "3   data/RAVDESS/Actor_01\\03-01-01-01-02-02-01.wav  neutral\n",
       "12  data/RAVDESS/Actor_01\\03-01-03-01-01-01-01.wav    happy"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAVDESS data\n",
    "ravdess_dir = 'data/RAVDESS/'\n",
    "\n",
    "ravdess_emotion_map = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "ravdess_files = []\n",
    "for root, _, files in os.walk(ravdess_dir):\n",
    "    for f in files:\n",
    "        if f.endswith('.wav'):\n",
    "            full_path = os.path.join(root, f)\n",
    "            ravdess_files.append(full_path)\n",
    "\n",
    "\n",
    "def extract_ravdess_label(filepath):\n",
    "    filename = os.path.basename(filepath)\n",
    "    parts = filename.split('-')\n",
    "    emotion_code = parts[2]\n",
    "    return ravdess_emotion_map.get(emotion_code)\n",
    "\n",
    "df_ravdess = pd.DataFrame({\n",
    "    'file': ravdess_files,\n",
    "    'label': [extract_ravdess_label(f) for f in ravdess_files]\n",
    "})\n",
    "\n",
    "# Filter out RAVDESS classes not in CREMA “calm” and “surprised”\n",
    "df_ravdess = df_ravdess[df_ravdess[\"label\"].isin([\"angry\",\"disgust\",\"fearful\",\"happy\",\"neutral\",\"sad\"])]\n",
    "\n",
    "# Drop  rows with unknown emotion code (just in case)\n",
    "df_ravdess = df_ravdess.dropna()\n",
    "df_ravdess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/CREMA\\1001_DFA_ANG_XX.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/CREMA\\1001_DFA_DIS_XX.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/CREMA\\1001_DFA_FEA_XX.wav</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/CREMA\\1001_DFA_HAP_XX.wav</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/CREMA\\1001_DFA_NEU_XX.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file    label\n",
       "0  data/CREMA\\1001_DFA_ANG_XX.wav    angry\n",
       "1  data/CREMA\\1001_DFA_DIS_XX.wav  disgust\n",
       "2  data/CREMA\\1001_DFA_FEA_XX.wav  fearful\n",
       "3  data/CREMA\\1001_DFA_HAP_XX.wav    happy\n",
       "4  data/CREMA\\1001_DFA_NEU_XX.wav  neutral"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine CREMA and RAVDESS\n",
    "label_map_crema = {\n",
    "    'ANG': 'angry',\n",
    "    'DIS': 'disgust',\n",
    "    'FEA': 'fearful',\n",
    "    'HAP': 'happy',\n",
    "    'NEU': 'neutral',\n",
    "    'SAD': 'sad'\n",
    "}\n",
    "df_crema['label'] = df_crema['label'].map(lambda l: label_map_crema.get(l.upper()))\n",
    "\n",
    "# Combine\n",
    "df_combined = pd.concat([df_crema, df_ravdess], ignore_index=True)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build label array\n",
    "labels = df_combined[\"label\"].values\n",
    "le = LabelEncoder()\n",
    "y_all = le.fit_transform(labels)  # numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\SFU\\Spring2025\\CMPT419\\Project\\ProjectCode\\CMPT419_Project\\419env\\Lib\\site-packages\\transformers\\configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (9554, 768)\n"
     ]
    }
   ],
   "source": [
    "# embeddings for each file\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(model_name=\"facebook/wav2vec2-base\", device=device)\n",
    "\n",
    "all_embeddings = []\n",
    "for i, row in df_combined.iterrows():\n",
    "    audio_path = row[\"file\"]\n",
    "    emb = feature_extractor.extract_embedding(audio_path)\n",
    "    all_embeddings.append(emb)\n",
    "\n",
    "all_embeddings = np.array(all_embeddings)  # shape [num_samples, 768]\n",
    "\n",
    "print(\"Embeddings shape:\", all_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_embeddings, y_all, test_size=0.25, stratify=y_all, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tone Classification model\n",
    "\n",
    "MLP trained on mean-pooled Wav2Vec2 audio embeddings and 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/50, Train Loss: 1.4541, Train Acc: 0.4131, Val Loss: 1.3333, Val Acc: 0.4738\n",
      "Epoch 2/50, Train Loss: 1.3521, Train Acc: 0.4525, Val Loss: 1.2383, Val Acc: 0.5059\n",
      "Epoch 3/50, Train Loss: 1.2870, Train Acc: 0.4894, Val Loss: 1.2406, Val Acc: 0.5101\n",
      "Epoch 4/50, Train Loss: 1.2496, Train Acc: 0.5120, Val Loss: 1.1922, Val Acc: 0.5318\n",
      "Epoch 5/50, Train Loss: 1.2344, Train Acc: 0.5152, Val Loss: 1.1630, Val Acc: 0.5457\n",
      "Epoch 6/50, Train Loss: 1.1961, Train Acc: 0.5337, Val Loss: 1.1577, Val Acc: 0.5520\n",
      "Epoch 7/50, Train Loss: 1.1786, Train Acc: 0.5363, Val Loss: 1.1519, Val Acc: 0.5485\n",
      "Epoch 8/50, Train Loss: 1.1359, Train Acc: 0.5663, Val Loss: 1.1669, Val Acc: 0.5373\n",
      "Epoch 9/50, Train Loss: 1.1118, Train Acc: 0.5645, Val Loss: 1.1552, Val Acc: 0.5401\n",
      "Epoch 10/50, Train Loss: 1.1036, Train Acc: 0.5715, Val Loss: 1.1201, Val Acc: 0.5597\n",
      "Epoch 11/50, Train Loss: 1.0680, Train Acc: 0.5790, Val Loss: 1.1366, Val Acc: 0.5618\n",
      "Epoch 12/50, Train Loss: 1.0765, Train Acc: 0.5844, Val Loss: 1.0975, Val Acc: 0.5673\n",
      "Epoch 13/50, Train Loss: 1.0484, Train Acc: 0.5982, Val Loss: 1.1278, Val Acc: 0.5618\n",
      "Epoch 14/50, Train Loss: 1.0479, Train Acc: 0.6042, Val Loss: 1.1166, Val Acc: 0.5757\n",
      "Epoch 15/50, Train Loss: 1.0231, Train Acc: 0.6048, Val Loss: 1.0983, Val Acc: 0.5869\n",
      "Epoch 16/50, Train Loss: 0.9810, Train Acc: 0.6239, Val Loss: 1.1347, Val Acc: 0.5639\n",
      "Epoch 17/50, Train Loss: 0.9642, Train Acc: 0.6307, Val Loss: 1.1102, Val Acc: 0.5701\n",
      "Early stopping at epoch 17\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.75      0.73      0.74       249\n",
      "     disgust       0.54      0.41      0.47       248\n",
      "     fearful       0.58      0.48      0.52       248\n",
      "       happy       0.53      0.49      0.51       248\n",
      "     neutral       0.47      0.78      0.59       192\n",
      "         sad       0.57      0.58      0.57       248\n",
      "\n",
      "    accuracy                           0.57      1433\n",
      "   macro avg       0.57      0.58      0.57      1433\n",
      "weighted avg       0.58      0.57      0.57      1433\n",
      "\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/50, Train Loss: 1.4523, Train Acc: 0.4136, Val Loss: 1.3639, Val Acc: 0.4299\n",
      "Epoch 2/50, Train Loss: 1.3251, Train Acc: 0.4738, Val Loss: 1.3609, Val Acc: 0.4648\n",
      "Epoch 3/50, Train Loss: 1.2843, Train Acc: 0.4895, Val Loss: 1.2809, Val Acc: 0.5108\n",
      "Epoch 4/50, Train Loss: 1.2143, Train Acc: 0.5279, Val Loss: 1.2435, Val Acc: 0.5157\n",
      "Epoch 5/50, Train Loss: 1.2122, Train Acc: 0.5215, Val Loss: 1.2302, Val Acc: 0.5269\n",
      "Epoch 6/50, Train Loss: 1.1807, Train Acc: 0.5384, Val Loss: 1.2699, Val Acc: 0.4948\n",
      "Epoch 7/50, Train Loss: 1.1675, Train Acc: 0.5396, Val Loss: 1.2290, Val Acc: 0.5129\n",
      "Epoch 8/50, Train Loss: 1.1371, Train Acc: 0.5584, Val Loss: 1.1754, Val Acc: 0.5513\n",
      "Epoch 9/50, Train Loss: 1.1124, Train Acc: 0.5689, Val Loss: 1.1860, Val Acc: 0.5394\n",
      "Epoch 10/50, Train Loss: 1.0952, Train Acc: 0.5815, Val Loss: 1.1623, Val Acc: 0.5548\n",
      "Epoch 11/50, Train Loss: 1.0541, Train Acc: 0.6015, Val Loss: 1.1768, Val Acc: 0.5625\n",
      "Epoch 12/50, Train Loss: 1.0580, Train Acc: 0.5860, Val Loss: 1.1609, Val Acc: 0.5597\n",
      "Epoch 13/50, Train Loss: 1.0352, Train Acc: 0.6055, Val Loss: 1.1657, Val Acc: 0.5506\n",
      "Epoch 14/50, Train Loss: 1.0149, Train Acc: 0.6083, Val Loss: 1.1903, Val Acc: 0.5576\n",
      "Epoch 15/50, Train Loss: 1.0277, Train Acc: 0.6036, Val Loss: 1.1449, Val Acc: 0.5639\n",
      "Epoch 16/50, Train Loss: 0.9773, Train Acc: 0.6206, Val Loss: 1.1661, Val Acc: 0.5583\n",
      "Epoch 17/50, Train Loss: 0.9704, Train Acc: 0.6226, Val Loss: 1.1653, Val Acc: 0.5604\n",
      "Epoch 18/50, Train Loss: 0.9718, Train Acc: 0.6265, Val Loss: 1.1482, Val Acc: 0.5687\n",
      "Epoch 19/50, Train Loss: 0.9587, Train Acc: 0.6282, Val Loss: 1.1371, Val Acc: 0.5757\n",
      "Epoch 20/50, Train Loss: 0.9347, Train Acc: 0.6368, Val Loss: 1.1341, Val Acc: 0.5946\n",
      "Epoch 21/50, Train Loss: 0.9303, Train Acc: 0.6476, Val Loss: 1.1756, Val Acc: 0.5527\n",
      "Epoch 22/50, Train Loss: 0.9107, Train Acc: 0.6452, Val Loss: 1.1188, Val Acc: 0.5834\n",
      "Epoch 23/50, Train Loss: 0.9070, Train Acc: 0.6540, Val Loss: 1.1841, Val Acc: 0.5659\n",
      "Epoch 24/50, Train Loss: 0.8994, Train Acc: 0.6568, Val Loss: 1.1384, Val Acc: 0.5687\n",
      "Epoch 25/50, Train Loss: 0.8685, Train Acc: 0.6785, Val Loss: 1.1642, Val Acc: 0.5862\n",
      "Epoch 26/50, Train Loss: 0.8889, Train Acc: 0.6694, Val Loss: 1.1578, Val Acc: 0.5729\n",
      "Epoch 27/50, Train Loss: 0.8544, Train Acc: 0.6757, Val Loss: 1.1488, Val Acc: 0.5785\n",
      "Early stopping at epoch 27\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.61      0.79      0.69       248\n",
      "     disgust       0.49      0.54      0.51       248\n",
      "     fearful       0.56      0.56      0.56       248\n",
      "       happy       0.62      0.40      0.48       248\n",
      "     neutral       0.57      0.62      0.60       192\n",
      "         sad       0.64      0.58      0.61       249\n",
      "\n",
      "    accuracy                           0.58      1433\n",
      "   macro avg       0.58      0.58      0.57      1433\n",
      "weighted avg       0.58      0.58      0.57      1433\n",
      "\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/50, Train Loss: 1.4341, Train Acc: 0.4389, Val Loss: 1.3942, Val Acc: 0.4285\n",
      "Epoch 2/50, Train Loss: 1.3119, Train Acc: 0.4834, Val Loss: 1.3091, Val Acc: 0.4731\n",
      "Epoch 3/50, Train Loss: 1.2672, Train Acc: 0.5105, Val Loss: 1.2736, Val Acc: 0.4913\n",
      "Epoch 4/50, Train Loss: 1.2244, Train Acc: 0.5152, Val Loss: 1.2576, Val Acc: 0.4892\n",
      "Epoch 5/50, Train Loss: 1.1974, Train Acc: 0.5302, Val Loss: 1.2347, Val Acc: 0.5087\n",
      "Epoch 6/50, Train Loss: 1.1707, Train Acc: 0.5440, Val Loss: 1.2672, Val Acc: 0.5108\n",
      "Epoch 7/50, Train Loss: 1.1646, Train Acc: 0.5452, Val Loss: 1.2111, Val Acc: 0.5248\n",
      "Epoch 8/50, Train Loss: 1.1102, Train Acc: 0.5736, Val Loss: 1.2099, Val Acc: 0.5199\n",
      "Epoch 9/50, Train Loss: 1.0926, Train Acc: 0.5780, Val Loss: 1.2201, Val Acc: 0.5206\n",
      "Epoch 10/50, Train Loss: 1.0794, Train Acc: 0.5862, Val Loss: 1.2039, Val Acc: 0.5324\n",
      "Epoch 11/50, Train Loss: 1.0488, Train Acc: 0.5963, Val Loss: 1.1868, Val Acc: 0.5345\n",
      "Epoch 12/50, Train Loss: 1.0553, Train Acc: 0.5968, Val Loss: 1.1905, Val Acc: 0.5408\n",
      "Epoch 13/50, Train Loss: 1.0197, Train Acc: 0.6125, Val Loss: 1.1802, Val Acc: 0.5471\n",
      "Epoch 14/50, Train Loss: 1.0131, Train Acc: 0.6148, Val Loss: 1.2164, Val Acc: 0.5171\n",
      "Epoch 15/50, Train Loss: 1.0058, Train Acc: 0.6162, Val Loss: 1.1586, Val Acc: 0.5464\n",
      "Epoch 16/50, Train Loss: 0.9962, Train Acc: 0.6216, Val Loss: 1.2009, Val Acc: 0.5541\n",
      "Epoch 17/50, Train Loss: 0.9616, Train Acc: 0.6350, Val Loss: 1.1743, Val Acc: 0.5436\n",
      "Epoch 18/50, Train Loss: 0.9431, Train Acc: 0.6521, Val Loss: 1.1764, Val Acc: 0.5338\n",
      "Epoch 19/50, Train Loss: 0.9467, Train Acc: 0.6366, Val Loss: 1.2010, Val Acc: 0.5345\n",
      "Epoch 20/50, Train Loss: 0.9427, Train Acc: 0.6385, Val Loss: 1.1625, Val Acc: 0.5492\n",
      "Early stopping at epoch 20\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.74      0.69      0.71       248\n",
      "     disgust       0.51      0.44      0.47       249\n",
      "     fearful       0.58      0.40      0.47       248\n",
      "       happy       0.48      0.57      0.52       248\n",
      "     neutral       0.53      0.67      0.59       192\n",
      "         sad       0.49      0.56      0.52       248\n",
      "\n",
      "    accuracy                           0.55      1433\n",
      "   macro avg       0.56      0.55      0.55      1433\n",
      "weighted avg       0.56      0.55      0.55      1433\n",
      "\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/50, Train Loss: 1.4564, Train Acc: 0.4163, Val Loss: 1.3243, Val Acc: 0.4689\n",
      "Epoch 2/50, Train Loss: 1.3511, Train Acc: 0.4641, Val Loss: 1.2690, Val Acc: 0.4885\n",
      "Epoch 3/50, Train Loss: 1.2921, Train Acc: 0.4890, Val Loss: 1.2295, Val Acc: 0.5101\n",
      "Epoch 4/50, Train Loss: 1.2442, Train Acc: 0.5127, Val Loss: 1.2198, Val Acc: 0.5150\n",
      "Epoch 5/50, Train Loss: 1.2200, Train Acc: 0.5197, Val Loss: 1.1771, Val Acc: 0.5457\n",
      "Epoch 6/50, Train Loss: 1.1877, Train Acc: 0.5288, Val Loss: 1.1531, Val Acc: 0.5485\n",
      "Epoch 7/50, Train Loss: 1.1752, Train Acc: 0.5434, Val Loss: 1.1615, Val Acc: 0.5436\n",
      "Epoch 8/50, Train Loss: 1.1461, Train Acc: 0.5509, Val Loss: 1.1651, Val Acc: 0.5450\n",
      "Epoch 9/50, Train Loss: 1.1126, Train Acc: 0.5778, Val Loss: 1.1480, Val Acc: 0.5429\n",
      "Epoch 10/50, Train Loss: 1.1088, Train Acc: 0.5782, Val Loss: 1.1607, Val Acc: 0.5471\n",
      "Epoch 11/50, Train Loss: 1.0783, Train Acc: 0.5834, Val Loss: 1.1573, Val Acc: 0.5492\n",
      "Epoch 12/50, Train Loss: 1.0469, Train Acc: 0.5972, Val Loss: 1.1282, Val Acc: 0.5541\n",
      "Epoch 13/50, Train Loss: 1.0435, Train Acc: 0.5970, Val Loss: 1.1314, Val Acc: 0.5583\n",
      "Epoch 14/50, Train Loss: 1.0374, Train Acc: 0.6073, Val Loss: 1.1547, Val Acc: 0.5297\n",
      "Epoch 15/50, Train Loss: 1.0303, Train Acc: 0.6097, Val Loss: 1.1262, Val Acc: 0.5618\n",
      "Epoch 16/50, Train Loss: 1.0084, Train Acc: 0.6127, Val Loss: 1.1304, Val Acc: 0.5618\n",
      "Epoch 17/50, Train Loss: 0.9827, Train Acc: 0.6251, Val Loss: 1.1784, Val Acc: 0.5450\n",
      "Epoch 18/50, Train Loss: 0.9728, Train Acc: 0.6268, Val Loss: 1.1342, Val Acc: 0.5722\n",
      "Epoch 19/50, Train Loss: 0.9489, Train Acc: 0.6331, Val Loss: 1.1257, Val Acc: 0.5785\n",
      "Epoch 20/50, Train Loss: 0.9298, Train Acc: 0.6452, Val Loss: 1.1455, Val Acc: 0.5771\n",
      "Epoch 21/50, Train Loss: 0.9167, Train Acc: 0.6528, Val Loss: 1.1355, Val Acc: 0.5701\n",
      "Epoch 22/50, Train Loss: 0.9119, Train Acc: 0.6595, Val Loss: 1.0903, Val Acc: 0.5869\n",
      "Epoch 23/50, Train Loss: 0.8964, Train Acc: 0.6633, Val Loss: 1.1189, Val Acc: 0.5827\n",
      "Epoch 24/50, Train Loss: 0.9009, Train Acc: 0.6530, Val Loss: 1.1577, Val Acc: 0.5701\n",
      "Epoch 25/50, Train Loss: 0.8822, Train Acc: 0.6657, Val Loss: 1.1365, Val Acc: 0.5820\n",
      "Epoch 26/50, Train Loss: 0.8763, Train Acc: 0.6706, Val Loss: 1.1246, Val Acc: 0.5736\n",
      "Epoch 27/50, Train Loss: 0.8479, Train Acc: 0.6820, Val Loss: 1.1485, Val Acc: 0.5729\n",
      "Early stopping at epoch 27\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.68      0.78      0.73       248\n",
      "     disgust       0.55      0.46      0.50       248\n",
      "     fearful       0.61      0.46      0.52       249\n",
      "       happy       0.54      0.50      0.52       248\n",
      "     neutral       0.51      0.63      0.57       192\n",
      "         sad       0.53      0.63      0.58       248\n",
      "\n",
      "    accuracy                           0.57      1433\n",
      "   macro avg       0.57      0.58      0.57      1433\n",
      "weighted avg       0.57      0.57      0.57      1433\n",
      "\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/50, Train Loss: 1.4454, Train Acc: 0.4166, Val Loss: 1.3504, Val Acc: 0.4550\n",
      "Epoch 2/50, Train Loss: 1.3306, Train Acc: 0.4714, Val Loss: 1.3002, Val Acc: 0.4913\n",
      "Epoch 3/50, Train Loss: 1.2804, Train Acc: 0.4974, Val Loss: 1.2770, Val Acc: 0.5038\n",
      "Epoch 4/50, Train Loss: 1.2274, Train Acc: 0.5204, Val Loss: 1.2625, Val Acc: 0.5038\n",
      "Epoch 5/50, Train Loss: 1.2043, Train Acc: 0.5220, Val Loss: 1.2224, Val Acc: 0.5157\n",
      "Epoch 6/50, Train Loss: 1.1924, Train Acc: 0.5394, Val Loss: 1.2262, Val Acc: 0.5178\n",
      "Epoch 7/50, Train Loss: 1.1561, Train Acc: 0.5499, Val Loss: 1.2578, Val Acc: 0.5080\n",
      "Epoch 8/50, Train Loss: 1.1087, Train Acc: 0.5722, Val Loss: 1.2185, Val Acc: 0.5304\n",
      "Epoch 9/50, Train Loss: 1.1208, Train Acc: 0.5649, Val Loss: 1.1752, Val Acc: 0.5401\n",
      "Epoch 10/50, Train Loss: 1.0840, Train Acc: 0.5853, Val Loss: 1.1807, Val Acc: 0.5415\n",
      "Epoch 11/50, Train Loss: 1.0782, Train Acc: 0.5867, Val Loss: 1.1758, Val Acc: 0.5262\n",
      "Epoch 12/50, Train Loss: 1.0406, Train Acc: 0.5977, Val Loss: 1.1605, Val Acc: 0.5422\n",
      "Epoch 13/50, Train Loss: 1.0508, Train Acc: 0.5982, Val Loss: 1.1562, Val Acc: 0.5352\n",
      "Epoch 14/50, Train Loss: 0.9967, Train Acc: 0.6247, Val Loss: 1.1746, Val Acc: 0.5464\n",
      "Epoch 15/50, Train Loss: 1.0238, Train Acc: 0.6062, Val Loss: 1.2071, Val Acc: 0.5192\n",
      "Epoch 16/50, Train Loss: 0.9774, Train Acc: 0.6354, Val Loss: 1.1956, Val Acc: 0.5499\n",
      "Epoch 17/50, Train Loss: 0.9360, Train Acc: 0.6354, Val Loss: 1.1491, Val Acc: 0.5562\n",
      "Epoch 18/50, Train Loss: 0.9417, Train Acc: 0.6434, Val Loss: 1.1389, Val Acc: 0.5569\n",
      "Epoch 19/50, Train Loss: 0.9485, Train Acc: 0.6382, Val Loss: 1.1528, Val Acc: 0.5527\n",
      "Epoch 20/50, Train Loss: 0.9537, Train Acc: 0.6293, Val Loss: 1.1423, Val Acc: 0.5597\n",
      "Epoch 21/50, Train Loss: 0.9310, Train Acc: 0.6464, Val Loss: 1.1814, Val Acc: 0.5506\n",
      "Epoch 22/50, Train Loss: 0.9155, Train Acc: 0.6509, Val Loss: 1.1668, Val Acc: 0.5387\n",
      "Epoch 23/50, Train Loss: 0.8995, Train Acc: 0.6537, Val Loss: 1.1616, Val Acc: 0.5513\n",
      "Early stopping at epoch 23\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.70      0.70      0.70       248\n",
      "     disgust       0.53      0.45      0.49       248\n",
      "     fearful       0.51      0.54      0.52       248\n",
      "       happy       0.56      0.39      0.46       249\n",
      "     neutral       0.48      0.77      0.59       192\n",
      "         sad       0.54      0.51      0.52       248\n",
      "\n",
      "    accuracy                           0.55      1433\n",
      "   macro avg       0.55      0.56      0.55      1433\n",
      "weighted avg       0.56      0.55      0.55      1433\n",
      "\n",
      "\n",
      "----- Average Accuracy over 5 folds: 0.5644 ± 0.0119\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "input_dim = all_embeddings.shape[1]\n",
    "output_dim = len(np.unique(y_all))\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "y_train_array = np.array(y_train)\n",
    "\n",
    "\n",
    "fold_accuracies = []\n",
    "best_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "# MLP classifier\n",
    "class ToneClassifierModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train_array)):\n",
    "    print(f\"\\n=== Fold {fold+1}/{n_splits} ===\")\n",
    "\n",
    "    X_fold_train = X_train[train_idx]\n",
    "    y_fold_train = y_train_array[train_idx]\n",
    "    X_fold_val = X_train[val_idx]\n",
    "    y_fold_val = y_train_array[val_idx]\n",
    "    \n",
    "    train_dataset = Wav2Vec2Dataset(X_fold_train, y_fold_train)\n",
    "    val_dataset = Wav2Vec2Dataset(X_fold_val, y_fold_val)\n",
    "\n",
    "    # WeightedRandomSampler\n",
    "    class_counts = np.bincount(y_fold_train)\n",
    "    weights_per_class = [len(y_fold_train)/c for c in class_counts]\n",
    "    sample_weights = [weights_per_class[label] for label in y_fold_train]\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "    # Create DataLoaders with WeightedRandomSampler for train\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler,  # No shuffle here\n",
    "        collate_fn=collate_fn_wav2vec2\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_wav2vec2)\n",
    "\n",
    "    model = ToneClassifierModel(input_dim, output_dim).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=7, factor=0.5)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss_sum = 0.0\n",
    "        train_preds, train_labels = [], []\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_sum += loss.item()\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "        train_loss = train_loss_sum / len(train_loader)\n",
    "        train_acc = accuracy_score(train_labels, train_preds)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        val_loss_sum = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                val_loss_sum += loss.item()\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(yb.cpu().numpy())\n",
    "        val_loss = val_loss_sum / len(val_loader)\n",
    "        val_acc = accuracy_score(all_labels, all_preds)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_state_dict = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    # Evaluate best state on val set\n",
    "    model.load_state_dict(best_state_dict)\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "    fold_acc = accuracy_score(all_labels, all_preds)\n",
    "    fold_accuracies.append(fold_acc)\n",
    "\n",
    "    if fold_acc > best_acc:\n",
    "        best_acc = fold_acc\n",
    "        best_model_state = best_state_dict\n",
    "\n",
    "    print(\"Fold Classification Report:\\n\",\n",
    "          classification_report(all_labels, all_preds, target_names=le.classes_))\n",
    "\n",
    "print(f\"\\n----- Average Accuracy over {n_splits} folds: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Evaluate best fold on Test Set -----\n",
      "Test Accuracy: 0.5823\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.64      0.80      0.71       414\n",
      "     disgust       0.55      0.57      0.56       414\n",
      "     fearful       0.54      0.54      0.54       414\n",
      "       happy       0.56      0.41      0.48       414\n",
      "     neutral       0.57      0.63      0.60       319\n",
      "         sad       0.60      0.55      0.57       414\n",
      "\n",
      "    accuracy                           0.58      2389\n",
      "   macro avg       0.58      0.58      0.58      2389\n",
      "weighted avg       0.58      0.58      0.58      2389\n",
      "\n",
      "(9554, 768)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on Test set with best fold model\n",
    "print(\"\\n----- Evaluate best fold on Test Set -----\")\n",
    "test_dataset = Wav2Vec2Dataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_wav2vec2)\n",
    "\n",
    "final_model = ToneClassifierModel(input_dim, output_dim).to(device)\n",
    "final_model.load_state_dict(best_model_state)\n",
    "\n",
    "# Save model\n",
    "torch.save({\n",
    "    'model_state_dict': final_model.state_dict(),\n",
    "    'label_encoder': le.classes_,  # Save label classes\n",
    "}, 'saved_models/tone_classifier.pth')\n",
    "\n",
    "\n",
    "final_model.eval()\n",
    "\n",
    "all_test_preds, all_test_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = final_model(xb)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_test_preds.extend(preds.cpu().numpy())\n",
    "        all_test_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "test_acc = accuracy_score(all_test_labels, all_test_preds)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"Test Classification Report:\\n\",\n",
    "      classification_report(all_test_labels, all_test_preds, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model on our own data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on our own data\n",
    "def predict_emotion(audio_path, model_path='saved_models/tone_classifier.pth'):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load model and label encoder\n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "\n",
    "    label_classes = checkpoint['label_encoder']\n",
    "    output_dim = len(label_classes)\n",
    "\n",
    "    input_dim = 768\n",
    "    model = ToneClassifierModel(input_dim=input_dim, output_dim=output_dim).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    # Extract Wav2Vec2 embedding\n",
    "    extractor = Wav2Vec2FeatureExtractor(model_name=\"facebook/wav2vec2-base\", device=device)\n",
    "    emb = extractor.extract_embedding(audio_path)  # shape [768]\n",
    "\n",
    "    # Convert to tensor\n",
    "    emb_tensor = torch.tensor(emb).unsqueeze(0).to(device)\n",
    "\n",
    "    # Predict with MLP\n",
    "    with torch.no_grad():\n",
    "        logits = model(emb_tensor)\n",
    "        pred_idx = torch.argmax(logits, dim=1).item()\n",
    "        predicted_emotion = label_classes[pred_idx]\n",
    "\n",
    "    return predicted_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion: disgust\n"
     ]
    }
   ],
   "source": [
    "test_path = \"data/Custom/01_Sahba_ANG.wav\"\n",
    "predicted = predict_emotion(test_path)\n",
    "print(\"Predicted Emotion:\", predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "419env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
