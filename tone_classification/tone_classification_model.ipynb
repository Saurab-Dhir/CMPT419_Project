{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tone Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "from data_loader import extract_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "\n",
    "wav_files_list = [f for f in os.listdir(data_dir) if f.endswith('.wav')]\n",
    "# print(wav_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/1001_DFA_ANG_XX.wav</td>\n",
       "      <td>ANG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/1001_DFA_DIS_XX.wav</td>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/1001_DFA_FEA_XX.wav</td>\n",
       "      <td>FEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/1001_DFA_HAP_XX.wav</td>\n",
       "      <td>HAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/1001_DFA_NEU_XX.wav</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file label\n",
       "0  data/1001_DFA_ANG_XX.wav   ANG\n",
       "1  data/1001_DFA_DIS_XX.wav   DIS\n",
       "2  data/1001_DFA_FEA_XX.wav   FEA\n",
       "3  data/1001_DFA_HAP_XX.wav   HAP\n",
       "4  data/1001_DFA_NEU_XX.wav   NEU"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the label out of file names\n",
    "data = []\n",
    "for file in wav_files_list:\n",
    "    parts = file.split('_')\n",
    "    if len(parts) > 2:\n",
    "        label = parts[2]\n",
    "        filepath = os.path.join(data_dir, file)\n",
    "        data.append({'file': filepath, 'label': label})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tone Classification model\n",
    "\n",
    "For lightweight tone classification we will use SVM and XGBoost. \n",
    "We use LSTMs for sequential tone analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    features = extract_features(row['file'])  # shape: (time_steps, feature_dim)\n",
    "    if features is not None:\n",
    "        feature_dim = features.shape[1]\n",
    "\n",
    "        # Pad or truncate to fixed length\n",
    "        if features.shape[0] > max_len:\n",
    "            features = features[:max_len, :]\n",
    "        elif features.shape[0] < max_len:\n",
    "            pad_width = max_len - features.shape[0]\n",
    "            pad = np.zeros((pad_width, feature_dim))\n",
    "            features = np.vstack([features, pad])\n",
    "\n",
    "        X.append(features)\n",
    "        y.append(row['label'])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode lables (converts emotions to numbers cause SVM only takes numerical values)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape = (samples, time_steps, feature_dim)\n",
    "n_samples, time_steps, n_features = X.shape\n",
    "\n",
    "# Flatten to 2D\n",
    "X_reshaped = X.reshape(-1, n_features)\n",
    "\n",
    "# Normalize across all frames and features\n",
    "scaler = StandardScaler()\n",
    "X_scaled_reshaped = scaler.fit_transform(X_reshaped)\n",
    "\n",
    "# Reshape back to original shape\n",
    "X_scaled = X_scaled_reshaped.reshape(n_samples, time_steps, n_features)\n",
    "\n",
    "# Now you can split and use in LSTM\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.25, stratify=y_encoded, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "# class CNNLSTMToneClassifier(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "#         super(CNNLSTMToneClassifier, self).__init__()\n",
    "\n",
    "#         self.cnn = nn.Sequential(\n",
    "#             nn.Conv1d(input_dim, 64, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(64),\n",
    "            \n",
    "#             nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.MaxPool1d(kernel_size=2)\n",
    "#         )\n",
    "\n",
    "#         self.lstm = nn.LSTM(input_size=128, hidden_size=hidden_dim, num_layers=2,\n",
    "#                             batch_first=True, dropout=0.3)\n",
    "\n",
    "#         self.fc_layers = nn.Sequential(\n",
    "#             nn.Linear(hidden_dim, hidden_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(hidden_dim, output_dim)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.transpose(1, 2)  # (B, F, T) for CNN\n",
    "#         x = self.cnn(x)  # (B, 128, T//2)\n",
    "#         x = x.transpose(1, 2)  # (B, T//2, 128) for LSTM\n",
    "#         _, (hn, _) = self.lstm(x)\n",
    "#         out = self.fc_layers(hn[-1]) # Use output from last LSTM layer\n",
    "#         return out\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, F)\n",
    "        weights = torch.softmax(self.attn(x), dim=1)  # (B, T, 1)\n",
    "        out = (x * weights).sum(dim=1)  # (B, F)\n",
    "        return out\n",
    "\n",
    "class CNNAttentionToneClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(CNNAttentionToneClassifier, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "\n",
    "            nn.Conv1d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128)\n",
    "        )\n",
    "\n",
    "        self.attention_pool = AttentionPooling(input_dim=128)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # (B, F, T)\n",
    "        x = self.cnn(x)        # (B, 128, T)\n",
    "        x = x.transpose(1, 2)  # (B, T, 128)\n",
    "        x = self.attention_pool(x)  # (B, 128)\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 01/50 | Train Loss: 1.6896 | Train Acc: 0.2070 | Val Loss: 1.7916 | Val Acc: 0.2113\n",
      "Epoch 02/50 | Train Loss: 1.6461 | Train Acc: 0.3233 | Val Loss: 1.6003 | Val Acc: 0.3178\n",
      "Epoch 03/50 | Train Loss: 1.5864 | Train Acc: 0.3640 | Val Loss: 1.5285 | Val Acc: 0.3563\n",
      "Epoch 04/50 | Train Loss: 1.5983 | Train Acc: 0.3255 | Val Loss: 1.5847 | Val Acc: 0.3250\n",
      "Epoch 05/50 | Train Loss: 1.5609 | Train Acc: 0.3589 | Val Loss: 1.5525 | Val Acc: 0.3581\n",
      "Epoch 06/50 | Train Loss: 1.5308 | Train Acc: 0.3766 | Val Loss: 1.4907 | Val Acc: 0.3733\n",
      "Epoch 07/50 | Train Loss: 1.5145 | Train Acc: 0.4068 | Val Loss: 1.4584 | Val Acc: 0.4029\n",
      "Epoch 08/50 | Train Loss: 1.5417 | Train Acc: 0.3535 | Val Loss: 1.5170 | Val Acc: 0.3563\n",
      "Epoch 09/50 | Train Loss: 1.5310 | Train Acc: 0.3963 | Val Loss: 1.4844 | Val Acc: 0.3966\n",
      "Epoch 10/50 | Train Loss: 1.4983 | Train Acc: 0.3905 | Val Loss: 1.4714 | Val Acc: 0.3832\n",
      "Epoch 11/50 | Train Loss: 1.4957 | Train Acc: 0.4066 | Val Loss: 1.4772 | Val Acc: 0.3930\n",
      "Epoch 12/50 | Train Loss: 1.4701 | Train Acc: 0.4223 | Val Loss: 1.4532 | Val Acc: 0.4127\n",
      "Epoch 13/50 | Train Loss: 1.4538 | Train Acc: 0.4319 | Val Loss: 1.4268 | Val Acc: 0.4288\n",
      "Epoch 14/50 | Train Loss: 1.4526 | Train Acc: 0.4272 | Val Loss: 1.4206 | Val Acc: 0.4181\n",
      "Epoch 15/50 | Train Loss: 1.4447 | Train Acc: 0.4373 | Val Loss: 1.4283 | Val Acc: 0.4252\n",
      "Epoch 16/50 | Train Loss: 1.4309 | Train Acc: 0.4489 | Val Loss: 1.4119 | Val Acc: 0.4270\n",
      "Epoch 17/50 | Train Loss: 1.4368 | Train Acc: 0.4541 | Val Loss: 1.4142 | Val Acc: 0.4288\n",
      "Epoch 18/50 | Train Loss: 1.4331 | Train Acc: 0.4339 | Val Loss: 1.4210 | Val Acc: 0.4261\n",
      "Epoch 19/50 | Train Loss: 1.3984 | Train Acc: 0.4485 | Val Loss: 1.4278 | Val Acc: 0.4315\n",
      "Epoch 20/50 | Train Loss: 1.3848 | Train Acc: 0.4675 | Val Loss: 1.3899 | Val Acc: 0.4485\n",
      "Epoch 21/50 | Train Loss: 1.3860 | Train Acc: 0.4442 | Val Loss: 1.4230 | Val Acc: 0.4118\n",
      "Epoch 22/50 | Train Loss: 1.3871 | Train Acc: 0.4621 | Val Loss: 1.4067 | Val Acc: 0.4423\n",
      "Epoch 23/50 | Train Loss: 1.3605 | Train Acc: 0.4819 | Val Loss: 1.3694 | Val Acc: 0.4476\n",
      "Epoch 24/50 | Train Loss: 1.3525 | Train Acc: 0.4922 | Val Loss: 1.3760 | Val Acc: 0.4664\n",
      "Epoch 25/50 | Train Loss: 1.3532 | Train Acc: 0.4933 | Val Loss: 1.3462 | Val Acc: 0.4628\n",
      "Epoch 26/50 | Train Loss: 1.3330 | Train Acc: 0.5045 | Val Loss: 1.3618 | Val Acc: 0.4637\n",
      "Epoch 27/50 | Train Loss: 1.3095 | Train Acc: 0.5132 | Val Loss: 1.3351 | Val Acc: 0.4709\n",
      "Epoch 28/50 | Train Loss: 1.2900 | Train Acc: 0.5166 | Val Loss: 1.3482 | Val Acc: 0.4816\n",
      "Epoch 29/50 | Train Loss: 1.2675 | Train Acc: 0.5007 | Val Loss: 1.3525 | Val Acc: 0.4557\n",
      "Epoch 30/50 | Train Loss: 1.2500 | Train Acc: 0.5488 | Val Loss: 1.3203 | Val Acc: 0.4915\n",
      "Epoch 31/50 | Train Loss: 1.2503 | Train Acc: 0.5318 | Val Loss: 1.3348 | Val Acc: 0.4673\n",
      "Epoch 32/50 | Train Loss: 1.2213 | Train Acc: 0.5417 | Val Loss: 1.3058 | Val Acc: 0.4924\n",
      "Epoch 33/50 | Train Loss: 1.2170 | Train Acc: 0.5670 | Val Loss: 1.2948 | Val Acc: 0.4906\n",
      "Epoch 34/50 | Train Loss: 1.1838 | Train Acc: 0.5791 | Val Loss: 1.2789 | Val Acc: 0.4879\n",
      "Epoch 35/50 | Train Loss: 1.1535 | Train Acc: 0.5688 | Val Loss: 1.3253 | Val Acc: 0.4834\n",
      "Epoch 36/50 | Train Loss: 1.1650 | Train Acc: 0.5918 | Val Loss: 1.2835 | Val Acc: 0.5157\n"
     ]
    }
   ],
   "source": [
    "#K-Fold Cross Validation on training set\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "input_dim = X_train.shape[2]\n",
    "hidden_dim = 32\n",
    "output_dim = len(np.unique(y_encoded))\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "\n",
    "fold_accuracies = []\n",
    "best_model = None\n",
    "best_acc = 0\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    print(f\"\\n=== Fold {fold+1}/{n_splits} ===\")\n",
    "\n",
    "    X_fold_train = X_train[train_idx]\n",
    "    y_fold_train = y_train[train_idx]\n",
    "    X_fold_val = X_train[val_idx]\n",
    "    y_fold_val = y_train[val_idx]\n",
    "\n",
    "    # Loaders\n",
    "    train_loader = DataLoader(TensorDataset(torch.tensor(X_fold_train, dtype=torch.float32),\n",
    "                                            torch.tensor(y_fold_train, dtype=torch.long)), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(torch.tensor(X_fold_val, dtype=torch.float32),\n",
    "                                          torch.tensor(y_fold_val, dtype=torch.long)), batch_size=batch_size)\n",
    "\n",
    "    # Model\n",
    "    # model = CNNLSTMToneClassifier(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "    model = CNNAttentionToneClassifier(input_dim=input_dim, output_dim=output_dim)\n",
    "\n",
    "\n",
    "    # Weighted loss\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(xb)\n",
    "            loss = criterion(outputs, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_train_loss / len(train_loader)\n",
    "\n",
    "        # Training accuracy\n",
    "        model.eval()\n",
    "        train_preds, train_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in train_loader:\n",
    "                outputs = model(xb)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_preds.extend(predicted.cpu().numpy())\n",
    "                train_labels.extend(yb.cpu().numpy())\n",
    "        train_acc = accuracy_score(train_labels, train_preds)\n",
    "\n",
    "        # Validation\n",
    "        all_preds, all_labels = [], []\n",
    "        val_loss_total = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                outputs = model(xb)\n",
    "                loss = criterion(outputs, yb)\n",
    "                val_loss_total += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss_total / len(val_loader)\n",
    "        val_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:02d}/{epochs} | Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    fold_acc = accuracy_score(all_labels, all_preds)\n",
    "    fold_accuracies.append(fold_acc)\n",
    "\n",
    "    if fold_acc > best_acc:\n",
    "        best_acc = fold_acc\n",
    "        best_model = model\n",
    "\n",
    "    print(\"Classification Report:\\n\", classification_report(all_labels, all_preds, target_names=le.classes_))\n",
    "\n",
    "print(f\"\\n=== Average Accuracy over {n_splits} folds: {np.mean(fold_accuracies):.4f} Â± {np.std(fold_accuracies):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "419env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
