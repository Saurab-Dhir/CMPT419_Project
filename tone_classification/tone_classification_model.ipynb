{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tone Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\SFU\\Spring2025\\CMPT419\\Project\\ProjectCode\\CMPT419_Project\\419env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler  \n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from data_loader import Wav2Vec2FeatureExtractor, Wav2Vec2Dataset, collate_fn_wav2vec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "CREMA D + RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/CREMA\\1001_DFA_ANG_XX.wav</td>\n",
       "      <td>ang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/CREMA\\1001_DFA_DIS_XX.wav</td>\n",
       "      <td>dis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/CREMA\\1001_DFA_FEA_XX.wav</td>\n",
       "      <td>fea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/CREMA\\1001_DFA_HAP_XX.wav</td>\n",
       "      <td>hap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/CREMA\\1001_DFA_NEU_XX.wav</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file label\n",
       "0  data/CREMA\\1001_DFA_ANG_XX.wav   ang\n",
       "1  data/CREMA\\1001_DFA_DIS_XX.wav   dis\n",
       "2  data/CREMA\\1001_DFA_FEA_XX.wav   fea\n",
       "3  data/CREMA\\1001_DFA_HAP_XX.wav   hap\n",
       "4  data/CREMA\\1001_DFA_NEU_XX.wav   neu"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREMA-D data\n",
    "crema_dir = 'data/CREMA'\n",
    "crema_files = [f for f in os.listdir(crema_dir) if f.endswith('.wav')]\n",
    "def extract_crema_label(filename):\n",
    "    return filename.split('_')[2].replace('.wav', '').lower()\n",
    "\n",
    "df_crema = pd.DataFrame({\n",
    "    'file': [os.path.join(crema_dir, f) for f in crema_files],\n",
    "    'label': [extract_crema_label(f) for f in crema_files]\n",
    "})\n",
    "\n",
    "df_crema.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/RAVDESS/Actor_01\\03-01-01-01-01-01-01.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/RAVDESS/Actor_01\\03-01-01-01-01-02-01.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/RAVDESS/Actor_01\\03-01-01-01-02-01-01.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/RAVDESS/Actor_01\\03-01-01-01-02-02-01.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/RAVDESS/Actor_01\\03-01-03-01-01-01-01.wav</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file    label\n",
       "0   data/RAVDESS/Actor_01\\03-01-01-01-01-01-01.wav  neutral\n",
       "1   data/RAVDESS/Actor_01\\03-01-01-01-01-02-01.wav  neutral\n",
       "2   data/RAVDESS/Actor_01\\03-01-01-01-02-01-01.wav  neutral\n",
       "3   data/RAVDESS/Actor_01\\03-01-01-01-02-02-01.wav  neutral\n",
       "12  data/RAVDESS/Actor_01\\03-01-03-01-01-01-01.wav    happy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAVDESS data\n",
    "ravdess_dir = 'data/RAVDESS/'\n",
    "\n",
    "ravdess_emotion_map = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "ravdess_files = []\n",
    "for root, _, files in os.walk(ravdess_dir):\n",
    "    for f in files:\n",
    "        if f.endswith('.wav'):\n",
    "            full_path = os.path.join(root, f)\n",
    "            ravdess_files.append(full_path)\n",
    "\n",
    "\n",
    "def extract_ravdess_label(filepath):\n",
    "    filename = os.path.basename(filepath)\n",
    "    parts = filename.split('-')\n",
    "    emotion_code = parts[2]\n",
    "    return ravdess_emotion_map.get(emotion_code)\n",
    "\n",
    "df_ravdess = pd.DataFrame({\n",
    "    'file': ravdess_files,\n",
    "    'label': [extract_ravdess_label(f) for f in ravdess_files]\n",
    "})\n",
    "\n",
    "# Filter out RAVDESS classes not in CREMA “calm” and “surprised”\n",
    "df_ravdess = df_ravdess[df_ravdess[\"label\"].isin([\"angry\",\"disgust\",\"fearful\",\"happy\",\"neutral\",\"sad\"])]\n",
    "\n",
    "# Drop  rows with unknown emotion code (just in case)\n",
    "df_ravdess = df_ravdess.dropna()\n",
    "df_ravdess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/CREMA\\1001_DFA_ANG_XX.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/CREMA\\1001_DFA_DIS_XX.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/CREMA\\1001_DFA_FEA_XX.wav</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/CREMA\\1001_DFA_HAP_XX.wav</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/CREMA\\1001_DFA_NEU_XX.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file    label\n",
       "0  data/CREMA\\1001_DFA_ANG_XX.wav    angry\n",
       "1  data/CREMA\\1001_DFA_DIS_XX.wav  disgust\n",
       "2  data/CREMA\\1001_DFA_FEA_XX.wav  fearful\n",
       "3  data/CREMA\\1001_DFA_HAP_XX.wav    happy\n",
       "4  data/CREMA\\1001_DFA_NEU_XX.wav  neutral"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine CREMA and RAVDESS\n",
    "label_map_crema = {\n",
    "    'ANG': 'angry',\n",
    "    'DIS': 'disgust',\n",
    "    'FEA': 'fearful',\n",
    "    'HAP': 'happy',\n",
    "    'NEU': 'neutral',\n",
    "    'SAD': 'sad'\n",
    "}\n",
    "df_crema['label'] = df_crema['label'].map(lambda l: label_map_crema.get(l.upper()))\n",
    "\n",
    "# Combine\n",
    "df_combined = pd.concat([df_crema, df_ravdess], ignore_index=True)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build label array\n",
    "labels = df_combined[\"label\"].values\n",
    "le = LabelEncoder()\n",
    "y_all = le.fit_transform(labels)  # numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\SFU\\Spring2025\\CMPT419\\Project\\ProjectCode\\CMPT419_Project\\419env\\Lib\\site-packages\\transformers\\configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (9554, 768)\n"
     ]
    }
   ],
   "source": [
    "# embeddings for each file\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(model_name=\"facebook/wav2vec2-base\", device=device)\n",
    "\n",
    "all_embeddings = []\n",
    "for i, row in df_combined.iterrows():\n",
    "    audio_path = row[\"file\"]\n",
    "    emb = feature_extractor.extract_embedding(audio_path)\n",
    "    all_embeddings.append(emb)\n",
    "\n",
    "all_embeddings = np.array(all_embeddings)  # shape [num_samples, 768]\n",
    "\n",
    "print(\"Embeddings shape:\", all_embeddings.shape)  # e.g. [N, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_embeddings, y_all, test_size=0.25, stratify=y_all, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tone Classification model\n",
    "\n",
    "MLP trained on mean-pooled Wav2Vec2 audio embeddings and 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/50, Train Loss: 1.4767, Train Acc: 0.4074, Val Loss: 1.3190, Val Acc: 0.4850\n",
      "Epoch 2/50, Train Loss: 1.3368, Train Acc: 0.4731, Val Loss: 1.2673, Val Acc: 0.4906\n",
      "Epoch 3/50, Train Loss: 1.3095, Train Acc: 0.4845, Val Loss: 1.2140, Val Acc: 0.5234\n",
      "Epoch 4/50, Train Loss: 1.2644, Train Acc: 0.5045, Val Loss: 1.2218, Val Acc: 0.4955\n",
      "Epoch 5/50, Train Loss: 1.2007, Train Acc: 0.5305, Val Loss: 1.1728, Val Acc: 0.5618\n",
      "Epoch 6/50, Train Loss: 1.1854, Train Acc: 0.5440, Val Loss: 1.1570, Val Acc: 0.5485\n",
      "Epoch 7/50, Train Loss: 1.1467, Train Acc: 0.5584, Val Loss: 1.1430, Val Acc: 0.5576\n",
      "Epoch 8/50, Train Loss: 1.1427, Train Acc: 0.5555, Val Loss: 1.1641, Val Acc: 0.5408\n",
      "Epoch 9/50, Train Loss: 1.1262, Train Acc: 0.5661, Val Loss: 1.1442, Val Acc: 0.5604\n",
      "Epoch 10/50, Train Loss: 1.0831, Train Acc: 0.5822, Val Loss: 1.1190, Val Acc: 0.5680\n",
      "Epoch 11/50, Train Loss: 1.0462, Train Acc: 0.5946, Val Loss: 1.1341, Val Acc: 0.5590\n",
      "Epoch 12/50, Train Loss: 1.0490, Train Acc: 0.5968, Val Loss: 1.1264, Val Acc: 0.5618\n",
      "Epoch 13/50, Train Loss: 1.0501, Train Acc: 0.6012, Val Loss: 1.1063, Val Acc: 0.5743\n",
      "Epoch 14/50, Train Loss: 1.0213, Train Acc: 0.6103, Val Loss: 1.1045, Val Acc: 0.5834\n",
      "Epoch 15/50, Train Loss: 1.0135, Train Acc: 0.6057, Val Loss: 1.1084, Val Acc: 0.5562\n",
      "Epoch 16/50, Train Loss: 0.9634, Train Acc: 0.6389, Val Loss: 1.1326, Val Acc: 0.5611\n",
      "Epoch 17/50, Train Loss: 0.9859, Train Acc: 0.6251, Val Loss: 1.0716, Val Acc: 0.5897\n",
      "Epoch 18/50, Train Loss: 0.9615, Train Acc: 0.6373, Val Loss: 1.0694, Val Acc: 0.5771\n",
      "Epoch 19/50, Train Loss: 0.9333, Train Acc: 0.6432, Val Loss: 1.0887, Val Acc: 0.5799\n",
      "Epoch 20/50, Train Loss: 0.9317, Train Acc: 0.6431, Val Loss: 1.1191, Val Acc: 0.5652\n",
      "Epoch 21/50, Train Loss: 0.9292, Train Acc: 0.6490, Val Loss: 1.0931, Val Acc: 0.5848\n",
      "Epoch 22/50, Train Loss: 0.9079, Train Acc: 0.6593, Val Loss: 1.0885, Val Acc: 0.5694\n",
      "Epoch 23/50, Train Loss: 0.8714, Train Acc: 0.6731, Val Loss: 1.0745, Val Acc: 0.6015\n",
      "Early stopping at epoch 23\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.65      0.81      0.72       249\n",
      "     disgust       0.59      0.54      0.56       248\n",
      "     fearful       0.62      0.47      0.54       248\n",
      "       happy       0.53      0.56      0.55       248\n",
      "     neutral       0.62      0.69      0.65       192\n",
      "         sad       0.60      0.55      0.58       248\n",
      "\n",
      "    accuracy                           0.60      1433\n",
      "   macro avg       0.60      0.60      0.60      1433\n",
      "weighted avg       0.60      0.60      0.60      1433\n",
      "\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/50, Train Loss: 1.4572, Train Acc: 0.4074, Val Loss: 1.3497, Val Acc: 0.4773\n",
      "Epoch 2/50, Train Loss: 1.3283, Train Acc: 0.4756, Val Loss: 1.2798, Val Acc: 0.5080\n",
      "Epoch 3/50, Train Loss: 1.2824, Train Acc: 0.4951, Val Loss: 1.2759, Val Acc: 0.5276\n",
      "Epoch 4/50, Train Loss: 1.2272, Train Acc: 0.5223, Val Loss: 1.2247, Val Acc: 0.5297\n",
      "Epoch 5/50, Train Loss: 1.1991, Train Acc: 0.5373, Val Loss: 1.2069, Val Acc: 0.5380\n",
      "Epoch 6/50, Train Loss: 1.1801, Train Acc: 0.5429, Val Loss: 1.1987, Val Acc: 0.5387\n",
      "Epoch 7/50, Train Loss: 1.1592, Train Acc: 0.5534, Val Loss: 1.2134, Val Acc: 0.5338\n",
      "Epoch 8/50, Train Loss: 1.1181, Train Acc: 0.5654, Val Loss: 1.2118, Val Acc: 0.5478\n",
      "Epoch 9/50, Train Loss: 1.1000, Train Acc: 0.5712, Val Loss: 1.1697, Val Acc: 0.5555\n",
      "Epoch 10/50, Train Loss: 1.0917, Train Acc: 0.5764, Val Loss: 1.1796, Val Acc: 0.5659\n",
      "Epoch 11/50, Train Loss: 1.0507, Train Acc: 0.5991, Val Loss: 1.1711, Val Acc: 0.5680\n",
      "Epoch 12/50, Train Loss: 1.0335, Train Acc: 0.6005, Val Loss: 1.1472, Val Acc: 0.5541\n",
      "Epoch 13/50, Train Loss: 1.0358, Train Acc: 0.6073, Val Loss: 1.1820, Val Acc: 0.5541\n",
      "Epoch 14/50, Train Loss: 1.0236, Train Acc: 0.6118, Val Loss: 1.1326, Val Acc: 0.5841\n",
      "Epoch 15/50, Train Loss: 1.0097, Train Acc: 0.6230, Val Loss: 1.1264, Val Acc: 0.5764\n",
      "Epoch 16/50, Train Loss: 0.9599, Train Acc: 0.6303, Val Loss: 1.1342, Val Acc: 0.5785\n",
      "Epoch 17/50, Train Loss: 0.9582, Train Acc: 0.6277, Val Loss: 1.1365, Val Acc: 0.5680\n",
      "Epoch 18/50, Train Loss: 0.9476, Train Acc: 0.6293, Val Loss: 1.1334, Val Acc: 0.5778\n",
      "Epoch 19/50, Train Loss: 0.9265, Train Acc: 0.6404, Val Loss: 1.1602, Val Acc: 0.5576\n",
      "Epoch 20/50, Train Loss: 0.9229, Train Acc: 0.6446, Val Loss: 1.1283, Val Acc: 0.5701\n",
      "Early stopping at epoch 20\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.61      0.83      0.71       248\n",
      "     disgust       0.56      0.56      0.56       248\n",
      "     fearful       0.52      0.52      0.52       248\n",
      "       happy       0.65      0.41      0.50       248\n",
      "     neutral       0.57      0.64      0.60       192\n",
      "         sad       0.51      0.47      0.49       249\n",
      "\n",
      "    accuracy                           0.57      1433\n",
      "   macro avg       0.57      0.57      0.56      1433\n",
      "weighted avg       0.57      0.57      0.56      1433\n",
      "\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/50, Train Loss: 1.4450, Train Acc: 0.4184, Val Loss: 1.3588, Val Acc: 0.4424\n",
      "Epoch 2/50, Train Loss: 1.3312, Train Acc: 0.4775, Val Loss: 1.3061, Val Acc: 0.4724\n",
      "Epoch 3/50, Train Loss: 1.2766, Train Acc: 0.4990, Val Loss: 1.2884, Val Acc: 0.4878\n",
      "Epoch 4/50, Train Loss: 1.2254, Train Acc: 0.5321, Val Loss: 1.2364, Val Acc: 0.5206\n",
      "Epoch 5/50, Train Loss: 1.1955, Train Acc: 0.5354, Val Loss: 1.2414, Val Acc: 0.5129\n",
      "Epoch 6/50, Train Loss: 1.1742, Train Acc: 0.5424, Val Loss: 1.2172, Val Acc: 0.5129\n",
      "Epoch 7/50, Train Loss: 1.1539, Train Acc: 0.5501, Val Loss: 1.2064, Val Acc: 0.5297\n",
      "Epoch 8/50, Train Loss: 1.1049, Train Acc: 0.5769, Val Loss: 1.1783, Val Acc: 0.5436\n",
      "Epoch 9/50, Train Loss: 1.1086, Train Acc: 0.5738, Val Loss: 1.2329, Val Acc: 0.5122\n",
      "Epoch 10/50, Train Loss: 1.0966, Train Acc: 0.5766, Val Loss: 1.1888, Val Acc: 0.5387\n",
      "Epoch 11/50, Train Loss: 1.0476, Train Acc: 0.5970, Val Loss: 1.1678, Val Acc: 0.5569\n",
      "Epoch 12/50, Train Loss: 1.0233, Train Acc: 0.6139, Val Loss: 1.1644, Val Acc: 0.5618\n",
      "Epoch 13/50, Train Loss: 1.0208, Train Acc: 0.6082, Val Loss: 1.1488, Val Acc: 0.5604\n",
      "Epoch 14/50, Train Loss: 1.0122, Train Acc: 0.6022, Val Loss: 1.1497, Val Acc: 0.5785\n",
      "Epoch 15/50, Train Loss: 0.9808, Train Acc: 0.6265, Val Loss: 1.1453, Val Acc: 0.5687\n",
      "Epoch 16/50, Train Loss: 0.9535, Train Acc: 0.6368, Val Loss: 1.1339, Val Acc: 0.5792\n",
      "Epoch 17/50, Train Loss: 0.9653, Train Acc: 0.6274, Val Loss: 1.1465, Val Acc: 0.5820\n",
      "Epoch 18/50, Train Loss: 0.9436, Train Acc: 0.6455, Val Loss: 1.1546, Val Acc: 0.5708\n",
      "Epoch 19/50, Train Loss: 0.9415, Train Acc: 0.6434, Val Loss: 1.1885, Val Acc: 0.5387\n",
      "Epoch 20/50, Train Loss: 0.9247, Train Acc: 0.6537, Val Loss: 1.1312, Val Acc: 0.5590\n",
      "Epoch 21/50, Train Loss: 0.9136, Train Acc: 0.6579, Val Loss: 1.1527, Val Acc: 0.5680\n",
      "Epoch 22/50, Train Loss: 0.8887, Train Acc: 0.6549, Val Loss: 1.1535, Val Acc: 0.5694\n",
      "Epoch 23/50, Train Loss: 0.8834, Train Acc: 0.6654, Val Loss: 1.1633, Val Acc: 0.5583\n",
      "Epoch 24/50, Train Loss: 0.8694, Train Acc: 0.6635, Val Loss: 1.1552, Val Acc: 0.5666\n",
      "Epoch 25/50, Train Loss: 0.8663, Train Acc: 0.6762, Val Loss: 1.2162, Val Acc: 0.5471\n",
      "Early stopping at epoch 25\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.67      0.77      0.72       248\n",
      "     disgust       0.57      0.41      0.48       249\n",
      "     fearful       0.56      0.43      0.49       248\n",
      "       happy       0.53      0.51      0.52       248\n",
      "     neutral       0.44      0.72      0.55       192\n",
      "         sad       0.54      0.47      0.50       248\n",
      "\n",
      "    accuracy                           0.55      1433\n",
      "   macro avg       0.55      0.55      0.54      1433\n",
      "weighted avg       0.55      0.55      0.54      1433\n",
      "\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/50, Train Loss: 1.4621, Train Acc: 0.4138, Val Loss: 1.3003, Val Acc: 0.4808\n",
      "Epoch 2/50, Train Loss: 1.3309, Train Acc: 0.4855, Val Loss: 1.2855, Val Acc: 0.4990\n",
      "Epoch 3/50, Train Loss: 1.2682, Train Acc: 0.5016, Val Loss: 1.2542, Val Acc: 0.5185\n",
      "Epoch 4/50, Train Loss: 1.2308, Train Acc: 0.5148, Val Loss: 1.2153, Val Acc: 0.5248\n",
      "Epoch 5/50, Train Loss: 1.2029, Train Acc: 0.5356, Val Loss: 1.1618, Val Acc: 0.5534\n",
      "Epoch 6/50, Train Loss: 1.1799, Train Acc: 0.5405, Val Loss: 1.1653, Val Acc: 0.5359\n",
      "Epoch 7/50, Train Loss: 1.1452, Train Acc: 0.5609, Val Loss: 1.1666, Val Acc: 0.5443\n",
      "Epoch 8/50, Train Loss: 1.1237, Train Acc: 0.5705, Val Loss: 1.1271, Val Acc: 0.5555\n",
      "Epoch 9/50, Train Loss: 1.1177, Train Acc: 0.5714, Val Loss: 1.1538, Val Acc: 0.5590\n",
      "Epoch 10/50, Train Loss: 1.0920, Train Acc: 0.5841, Val Loss: 1.1314, Val Acc: 0.5562\n",
      "Epoch 11/50, Train Loss: 1.0572, Train Acc: 0.5939, Val Loss: 1.1602, Val Acc: 0.5478\n",
      "Epoch 12/50, Train Loss: 1.0351, Train Acc: 0.5984, Val Loss: 1.1174, Val Acc: 0.5548\n",
      "Epoch 13/50, Train Loss: 1.0273, Train Acc: 0.6117, Val Loss: 1.1327, Val Acc: 0.5611\n",
      "Epoch 14/50, Train Loss: 1.0254, Train Acc: 0.5980, Val Loss: 1.1645, Val Acc: 0.5492\n",
      "Epoch 15/50, Train Loss: 1.0154, Train Acc: 0.6157, Val Loss: 1.1108, Val Acc: 0.5785\n",
      "Epoch 16/50, Train Loss: 0.9567, Train Acc: 0.6340, Val Loss: 1.0876, Val Acc: 0.5799\n",
      "Epoch 17/50, Train Loss: 0.9698, Train Acc: 0.6225, Val Loss: 1.1181, Val Acc: 0.5799\n",
      "Epoch 18/50, Train Loss: 0.9635, Train Acc: 0.6312, Val Loss: 1.0910, Val Acc: 0.5813\n",
      "Epoch 19/50, Train Loss: 0.9562, Train Acc: 0.6333, Val Loss: 1.1074, Val Acc: 0.5722\n",
      "Epoch 20/50, Train Loss: 0.9121, Train Acc: 0.6493, Val Loss: 1.1314, Val Acc: 0.5743\n",
      "Epoch 21/50, Train Loss: 0.9190, Train Acc: 0.6492, Val Loss: 1.0973, Val Acc: 0.5883\n",
      "Early stopping at epoch 21\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.72      0.81      0.76       248\n",
      "     disgust       0.62      0.47      0.53       248\n",
      "     fearful       0.56      0.49      0.52       249\n",
      "       happy       0.60      0.49      0.54       248\n",
      "     neutral       0.51      0.67      0.58       192\n",
      "         sad       0.52      0.63      0.57       248\n",
      "\n",
      "    accuracy                           0.59      1433\n",
      "   macro avg       0.59      0.59      0.58      1433\n",
      "weighted avg       0.59      0.59      0.58      1433\n",
      "\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/50, Train Loss: 1.4359, Train Acc: 0.4278, Val Loss: 1.3575, Val Acc: 0.4529\n",
      "Epoch 2/50, Train Loss: 1.3263, Train Acc: 0.4843, Val Loss: 1.3152, Val Acc: 0.4759\n",
      "Epoch 3/50, Train Loss: 1.2807, Train Acc: 0.5068, Val Loss: 1.3008, Val Acc: 0.4983\n",
      "Epoch 4/50, Train Loss: 1.2272, Train Acc: 0.5143, Val Loss: 1.2442, Val Acc: 0.5073\n",
      "Epoch 5/50, Train Loss: 1.1972, Train Acc: 0.5394, Val Loss: 1.2198, Val Acc: 0.5213\n",
      "Epoch 6/50, Train Loss: 1.1632, Train Acc: 0.5448, Val Loss: 1.2460, Val Acc: 0.5122\n",
      "Epoch 7/50, Train Loss: 1.1679, Train Acc: 0.5504, Val Loss: 1.2472, Val Acc: 0.5038\n",
      "Epoch 8/50, Train Loss: 1.1107, Train Acc: 0.5707, Val Loss: 1.2183, Val Acc: 0.5297\n",
      "Epoch 9/50, Train Loss: 1.0952, Train Acc: 0.5747, Val Loss: 1.2407, Val Acc: 0.5255\n",
      "Epoch 10/50, Train Loss: 1.0932, Train Acc: 0.5815, Val Loss: 1.2146, Val Acc: 0.5499\n",
      "Epoch 11/50, Train Loss: 1.0536, Train Acc: 0.5960, Val Loss: 1.1566, Val Acc: 0.5513\n",
      "Epoch 12/50, Train Loss: 1.0380, Train Acc: 0.6110, Val Loss: 1.1847, Val Acc: 0.5436\n",
      "Epoch 13/50, Train Loss: 1.0429, Train Acc: 0.5970, Val Loss: 1.1637, Val Acc: 0.5394\n",
      "Epoch 14/50, Train Loss: 1.0045, Train Acc: 0.6190, Val Loss: 1.1996, Val Acc: 0.5464\n",
      "Epoch 15/50, Train Loss: 1.0189, Train Acc: 0.6103, Val Loss: 1.1794, Val Acc: 0.5513\n",
      "Epoch 16/50, Train Loss: 0.9557, Train Acc: 0.6417, Val Loss: 1.1504, Val Acc: 0.5632\n",
      "Epoch 17/50, Train Loss: 0.9987, Train Acc: 0.6155, Val Loss: 1.1343, Val Acc: 0.5583\n",
      "Epoch 18/50, Train Loss: 0.9640, Train Acc: 0.6397, Val Loss: 1.1180, Val Acc: 0.5890\n",
      "Epoch 19/50, Train Loss: 0.9390, Train Acc: 0.6366, Val Loss: 1.1387, Val Acc: 0.5499\n",
      "Epoch 20/50, Train Loss: 0.9579, Train Acc: 0.6378, Val Loss: 1.1819, Val Acc: 0.5527\n",
      "Epoch 21/50, Train Loss: 0.9228, Train Acc: 0.6478, Val Loss: 1.1686, Val Acc: 0.5604\n",
      "Epoch 22/50, Train Loss: 0.8964, Train Acc: 0.6572, Val Loss: 1.1321, Val Acc: 0.5785\n",
      "Epoch 23/50, Train Loss: 0.8931, Train Acc: 0.6628, Val Loss: 1.1734, Val Acc: 0.5562\n",
      "Early stopping at epoch 23\n",
      "Fold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.63      0.72      0.67       248\n",
      "     disgust       0.56      0.52      0.54       248\n",
      "     fearful       0.54      0.47      0.50       248\n",
      "       happy       0.57      0.38      0.45       249\n",
      "     neutral       0.54      0.54      0.54       192\n",
      "         sad       0.50      0.71      0.59       248\n",
      "\n",
      "    accuracy                           0.56      1433\n",
      "   macro avg       0.56      0.56      0.55      1433\n",
      "weighted avg       0.56      0.56      0.55      1433\n",
      "\n",
      "\n",
      "----- Average Accuracy over 5 folds: 0.5726 ± 0.0200\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "input_dim = all_embeddings.shape[1]\n",
    "output_dim = len(np.unique(y_all))\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "y_train_array = np.array(y_train)\n",
    "\n",
    "\n",
    "fold_accuracies = []\n",
    "best_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "# MLP classifier\n",
    "class ToneClassifierModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train_array)):\n",
    "    print(f\"\\n=== Fold {fold+1}/{n_splits} ===\")\n",
    "\n",
    "    X_fold_train = X_train[train_idx]\n",
    "    y_fold_train = y_train_array[train_idx]\n",
    "    X_fold_val = X_train[val_idx]\n",
    "    y_fold_val = y_train_array[val_idx]\n",
    "    \n",
    "    train_dataset = Wav2Vec2Dataset(X_fold_train, y_fold_train)\n",
    "    val_dataset = Wav2Vec2Dataset(X_fold_val, y_fold_val)\n",
    "\n",
    "\n",
    "    # WeightedRandomSampler\n",
    "    class_counts = np.bincount(y_fold_train)\n",
    "    weights_per_class = [len(y_fold_train)/c for c in class_counts]\n",
    "    sample_weights = [weights_per_class[label] for label in y_fold_train]\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "    # Create DataLoaders with WeightedRandomSampler for train\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler,  # No shuffle here\n",
    "        collate_fn=collate_fn_wav2vec2\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_wav2vec2)\n",
    "\n",
    "    model = ToneClassifierModel(input_dim, output_dim).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=7, factor=0.5)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss_sum = 0.0\n",
    "        train_preds, train_labels = [], []\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_sum += loss.item()\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "        train_loss = train_loss_sum / len(train_loader)\n",
    "        train_acc = accuracy_score(train_labels, train_preds)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        val_loss_sum = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                val_loss_sum += loss.item()\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(yb.cpu().numpy())\n",
    "        val_loss = val_loss_sum / len(val_loader)\n",
    "        val_acc = accuracy_score(all_labels, all_preds)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_state_dict = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    # Evaluate best state on val set\n",
    "    model.load_state_dict(best_state_dict)\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "    fold_acc = accuracy_score(all_labels, all_preds)\n",
    "    fold_accuracies.append(fold_acc)\n",
    "\n",
    "    if fold_acc > best_acc:\n",
    "        best_acc = fold_acc\n",
    "        best_model_state = best_state_dict\n",
    "\n",
    "    print(\"Fold Classification Report:\\n\",\n",
    "          classification_report(all_labels, all_preds, target_names=le.classes_))\n",
    "\n",
    "print(f\"\\n----- Average Accuracy over {n_splits} folds: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Evaluate best fold on Test Set -----\n",
      "Test Accuracy: 0.5663\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.62      0.81      0.70       414\n",
      "     disgust       0.54      0.48      0.51       414\n",
      "     fearful       0.61      0.44      0.51       414\n",
      "       happy       0.48      0.54      0.51       414\n",
      "     neutral       0.59      0.58      0.59       319\n",
      "         sad       0.57      0.55      0.56       414\n",
      "\n",
      "    accuracy                           0.57      2389\n",
      "   macro avg       0.57      0.57      0.56      2389\n",
      "weighted avg       0.57      0.57      0.56      2389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on Test set with best fold model\n",
    "print(\"\\n----- Evaluate best fold on Test Set -----\")\n",
    "test_dataset = Wav2Vec2Dataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_wav2vec2)\n",
    "\n",
    "final_model = ToneClassifierModel(input_dim, output_dim).to(device)\n",
    "final_model.load_state_dict(best_model_state)\n",
    "\n",
    "# Save model\n",
    "torch.save({\n",
    "    'model_state_dict': final_model.state_dict(),\n",
    "    'label_encoder': le.classes_,  # Save label classes\n",
    "}, 'saved_models/tone_classifier.pth')\n",
    "\n",
    "\n",
    "final_model.eval()\n",
    "\n",
    "all_test_preds, all_test_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = final_model(xb)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_test_preds.extend(preds.cpu().numpy())\n",
    "        all_test_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "test_acc = accuracy_score(all_test_labels, all_test_preds)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"Test Classification Report:\\n\",\n",
    "      classification_report(all_test_labels, all_test_preds, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model on our own data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on our own data\n",
    "def predict_emotion(audio_path, model_path='saved_models/tone_classifier.pth'):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load model and label encoder\n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "\n",
    "    label_classes = checkpoint['label_encoder']\n",
    "    output_dim = len(label_classes)\n",
    "\n",
    "    # Model expects input_dim = 774\n",
    "    input_dim = 768\n",
    "    model = ToneClassifierModel(input_dim=input_dim, output_dim=output_dim).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    # Extract Wav2Vec2 embedding\n",
    "    extractor = Wav2Vec2FeatureExtractor(model_name=\"facebook/wav2vec2-base\", device=device)\n",
    "    emb = extractor.extract_embedding(audio_path)  # shape [768]\n",
    "\n",
    "    # Convert to tensor\n",
    "    emb_tensor = torch.tensor(emb).unsqueeze(0).to(device)\n",
    "\n",
    "    # Predict with MLP\n",
    "    with torch.no_grad():\n",
    "        logits = model(emb_tensor)\n",
    "        pred_idx = torch.argmax(logits, dim=1).item()\n",
    "        predicted_emotion = label_classes[pred_idx]\n",
    "\n",
    "    return predicted_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion: angry\n"
     ]
    }
   ],
   "source": [
    "test_path = \"data/test/ANG.wav\"\n",
    "predicted = predict_emotion(test_path)\n",
    "print(\"Predicted Emotion:\", predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "419env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
